# backend/rag_pipeline.py
"""
RAG æ ¸å¿ƒæµç¨‹ï¼šæ–‡æ¡£åŠ è½½ â†’ åˆ†å— â†’ å‘é‡åŒ– â†’ æ£€ç´¢
"""
import os
import numpy as np
import streamlit as st
from sklearn.metrics.pairwise import cosine_similarity
from langchain_text_splitters import RecursiveCharacterTextSplitter
from sentence_transformers import SentenceTransformer
from openai import OpenAI

# ===========================================
# ğŸ”§ å¯é…ç½®å‚æ•°
# ===========================================
USE_OPENAI_EMBEDDING = True   # æ”¹ä¸º True åˆ™ä½¿ç”¨ OpenAI embedding
CHUNK_SIZE = 500
CHUNK_OVERLAP = 100
EMBED_DIM = 384   # all-MiniLM-L6-v2 è¾“å‡ºç»´åº¦
# ===========================================

# âœ… æ¨¡å‹åˆå§‹åŒ–
if USE_OPENAI_EMBEDDING:
    client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
    def embed_texts(texts):
        resp = client.embeddings.create(
            input=texts,
            model="text-embedding-3-small"
        )
        return np.array([d.embedding for d in resp.data])
else:
    embedder = SentenceTransformer('all-MiniLM-L6-v2')
    def embed_texts(texts):
        return embedder.encode(texts, convert_to_numpy=True, normalize_embeddings=True)

# ===========================================
# ğŸ§© å…¨å±€å­˜å‚¨
# ===========================================
VEC_STORE = {
    "texts": [],
    "embeddings": None
}

# ===========================================
# ğŸ“„ æ–‡æœ¬åˆ†å—ï¼ˆæ”¹è¿›ç­–ç•¥ï¼‰
# ===========================================
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=CHUNK_SIZE,
    chunk_overlap=CHUNK_OVERLAP,
    separators=[".", "!", "?", "\n\n", "\n", " "],
)

def extract_text_from_pdf(file_obj):
    import fitz
    file_obj.seek(0)
    text = ""
    with fitz.open(stream=file_obj.read(), filetype="pdf") as doc:
        for page in doc:
            text += page.get_text()
    return text.strip()

# ===========================================
# ğŸš€ æ„å»ºçŸ¥è¯†åº“
# ===========================================
def add_document_from_file(raw_text, file_type="txt"):
    from backend.embeddings import is_fitted  # å¯ä¿ç•™åŸç»“æ„
    text = extract_text_from_pdf(raw_text) if file_type == "pdf" else raw_text.strip()
    if not text:
        raise ValueError("âŒ No text extracted from document.")
    chunks = text_splitter.split_text(text)
    print(f"[INFO] æ–‡æœ¬åˆ†å—å®Œæˆï¼Œå…± {len(chunks)} æ®µ")

    VEC_STORE["texts"] = chunks
    VEC_STORE["embeddings"] = embed_texts(chunks)
    print(f"[INFO] å‘é‡åŒ–å®Œæˆï¼Œå½¢çŠ¶ {VEC_STORE['embeddings'].shape}")

def query_rag(question: str, top_k=8):
    """
    RAG æ£€ç´¢ + ç”Ÿæˆï¼š
    ä» VEC_STORE ä¸­æ£€ç´¢æœ€ç›¸å…³çš„æ–‡æœ¬ç‰‡æ®µï¼Œç„¶åç”¨ LLM ç”Ÿæˆå›ç­”ã€‚
    """

    texts = VEC_STORE.get("texts")
    embeddings = VEC_STORE.get("embeddings")

    # 1ï¸âƒ£ å¦‚æœå½“å‰å‘é‡åº“é‡Œå®Œå…¨æ²¡æœ‰ä¸œè¥¿ï¼Œå°±æç¤ºâ€œæ— çŸ¥è¯†åº“â€
    if not texts or embeddings is None or len(texts) == 0:
        return (
            "ğŸ“­ No knowledge base available.\n\n"
            "Please upload a contract OR ask your landlord to upload a house knowledge base."
        )

    # 2ï¸âƒ£ å¯¹é—®é¢˜åš embedding
    q_emb = embed_texts([question])
    sims = cosine_similarity(q_emb, embeddings)[0]
    top_idx = np.argsort(sims)[-top_k:][::-1]
    context = "\n\n".join([texts[i] for i in top_idx])

    # 3ï¸âƒ£ æ„é€  prompt
    prompt = f"""
    You are an intelligent rental & contract assistant. 
    Your task is to answer the user's question using the provided context. 

    Follow these rules:

    1. **If the question asks for a summary, overview, outline, key points, main ideas, or general description**, 
    then generate a high-quality summary *based on the context*, even if it does not explicitly contain headings.

    2. **If the question is factual (dates, responsibilities, clauses, fees, etc.)**, 
    answer ONLY using information found in the context. Do not fabricate missing facts.

    3. **If the context does not contain the required factual information**, 
    respond naturally:  
    â€œThe provided documents do not mention this information.â€

    4. **Do NOT mention that you used a knowledge base. Do NOT show the context.**

    <context>
    {context}
    </context>

    <question>
    {question}
    </question>

    Provide the best possible answer:
    """


    if USE_OPENAI_EMBEDDING:
        client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
        resp = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are a professional contract Q&A assistant."},
                {"role": "user", "content": prompt},
            ],
            temperature=0.3,
            max_tokens=512,
        )
        return resp.choices[0].message.content.strip()
    else:
        # ä¸è°ƒç”¨ LLM æ—¶ï¼Œç›´æ¥æŠŠæ£€ç´¢ç»“æœè¿”å›
        return (
            "ğŸ“„ Most relevant context:\n\n"
            + context[:800]
            + "\n\n(A final answer should be generated by a language model based on the retrieved context)"
        )


# ===========================================
# âœ… å·¥å…·å‡½æ•°
# ===========================================
def is_fitted():
    return VEC_STORE["embeddings"] is not None
