# backend/rag_pipeline.py
"""
RAG æ ¸å¿ƒæµç¨‹ï¼šæ–‡æ¡£åŠ è½½ â†’ åˆ†å— â†’ å‘é‡åŒ– â†’ æ£€ç´¢
"""
import os
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from langchain_text_splitters import RecursiveCharacterTextSplitter
from sentence_transformers import SentenceTransformer
from openai import OpenAI

# ===========================================
# ğŸ”§ å¯é…ç½®å‚æ•°
# ===========================================
USE_OPENAI_EMBEDDING = True   # æ”¹ä¸º True åˆ™ä½¿ç”¨ OpenAI embedding
CHUNK_SIZE = 500
CHUNK_OVERLAP = 100
EMBED_DIM = 384   # all-MiniLM-L6-v2 è¾“å‡ºç»´åº¦
# ===========================================

# âœ… æ¨¡å‹åˆå§‹åŒ–
if USE_OPENAI_EMBEDDING:
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    def embed_texts(texts):
        resp = client.embeddings.create(
            input=texts,
            model="text-embedding-3-small"
        )
        return np.array([d.embedding for d in resp.data])
else:
    embedder = SentenceTransformer('all-MiniLM-L6-v2')
    def embed_texts(texts):
        return embedder.encode(texts, convert_to_numpy=True, normalize_embeddings=True)

# ===========================================
# ğŸ§© å…¨å±€å­˜å‚¨
# ===========================================
VEC_STORE = {
    "texts": [],
    "embeddings": None
}

# ===========================================
# ğŸ“„ æ–‡æœ¬åˆ†å—ï¼ˆæ”¹è¿›ç­–ç•¥ï¼‰
# ===========================================
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=CHUNK_SIZE,
    chunk_overlap=CHUNK_OVERLAP,
    separators=[".", "!", "?", "\n\n", "\n", " "],
)

def extract_text_from_pdf(file_obj):
    import fitz
    file_obj.seek(0)
    text = ""
    with fitz.open(stream=file_obj.read(), filetype="pdf") as doc:
        for page in doc:
            text += page.get_text()
    return text.strip()

# ===========================================
# ğŸš€ æ„å»ºçŸ¥è¯†åº“
# ===========================================
def add_document_from_file(raw_text, file_type="txt"):
    from backend.embeddings import is_fitted  # å¯ä¿ç•™åŸç»“æ„
    text = extract_text_from_pdf(raw_text) if file_type == "pdf" else raw_text.strip()
    if not text:
        raise ValueError("âŒ No text extracted from document.")
    chunks = text_splitter.split_text(text)
    print(f"[INFO] æ–‡æœ¬åˆ†å—å®Œæˆï¼Œå…± {len(chunks)} æ®µ")

    VEC_STORE["texts"] = chunks
    VEC_STORE["embeddings"] = embed_texts(chunks)
    print(f"[INFO] å‘é‡åŒ–å®Œæˆï¼Œå½¢çŠ¶ {VEC_STORE['embeddings'].shape}")

# ===========================================
# ğŸ” æ£€ç´¢ + ç”Ÿæˆ
# ===========================================
def query_rag(question: str, top_k=8):
    if VEC_STORE["embeddings"] is None:
        return "âŒ Please first upload and index the"

    q_emb = embed_texts([question])
    sims = cosine_similarity(q_emb, VEC_STORE["embeddings"])[0]
    top_idx = np.argsort(sims)[-top_k:][::-1]
    context = "\n\n".join([VEC_STORE["texts"][i] for i in top_idx])

    # ğŸ”¹ ç”Ÿæˆå›ç­”
    # ğŸ”¹ Generate response
    prompt = f"""
You are an intelligent contract assistant. Please answer the question based on the following context. Do not fabricate information.

<context>
{context}
</context>

<question>
{question}
</question>

<answer>
"""
    if USE_OPENAI_EMBEDDING:
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        resp = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are a professional contract Q&A assistant."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=512
        )
        return resp.choices[0].message.content.strip()
    else:
        # ğŸ”¹ If not connecting to OpenAI for now, return retrieval result instead
        return f"ğŸ“„ Most relevant context:\n\n{context[:800]}...\n\n(A final answer should be generated by a language model based on the retrieved context)"

# ===========================================
# âœ… å·¥å…·å‡½æ•°
# ===========================================
def is_fitted():
    return VEC_STORE["embeddings"] is not None
