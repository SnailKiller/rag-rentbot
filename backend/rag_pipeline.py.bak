# backend/rag_pipeline.py
"""
RAG æ ¸å¿ƒæµç¨‹ï¼šæ–‡æ¡£åŠ è½½ â†’ åˆ†å— â†’ å‘é‡åŒ– â†’ æ£€ç´¢
"""
from typing import List
import fitz
from backend.embeddings import build_embeddings, get_embeddings, get_texts, is_fitted
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import os
from langchain_text_splitters import RecursiveCharacterTextSplitter

# âœ… æ·»åŠ  OpenAI
from openai import OpenAI

# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),  # åœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½®
)


# ğŸ“„ æ–‡æœ¬åˆ†å—å™¨ï¼ˆä¿å®ˆé…ç½®ï¼‰
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=300,      # æ¯å— 300 å­—ç¬¦ï¼ˆçº¦ 50-100 è¯ï¼‰
    chunk_overlap=50,    # é‡å é¿å…æ–­å¥
    separators=["\n\n", "\n", "ã€‚", " ", ""]
)

def extract_text_from_pdf(file_obj) -> str:
    """
    ä½¿ç”¨ PyMuPDF (fitz) ä» PDF æå–æ–‡æœ¬
    """
    file_obj.seek(0)
    try:
        doc = fitz.open(stream=file_obj.read(), filetype="pdf")
        text = ""
        for page in doc:
            text += page.get_text()  # é«˜è´¨é‡æ–‡æœ¬æå–
        doc.close()
        return text.strip()
    except Exception as e:
        raise RuntimeError(f"Failed to extract text with PyMuPDF: {e}")

def add_document_from_file(raw_text, file_type: str = "txt"):
    if file_type == "pdf":
        text = extract_text_from_pdf(raw_text)
    else:
        text = raw_text.strip()

    if not text:
        raise ValueError("âŒ No text extracted from document.")

    print(f"[INFO] ğŸ“„ Extracted {len(text)} characters")
    chunks = text_splitter.split_text(text)
    print(f"[INFO] ğŸ“„ Split into {len(chunks)} chunks")

    build_embeddings(chunks)
    print(f"[INFO] ğŸš€ Built knowledge base with {len(chunks)} chunks")


def query_rag(question: str, top_k: int = 3) -> str:
    """
    RAG: æ£€ç´¢ + ç”Ÿæˆï¼ˆä½¿ç”¨ OpenAI APIï¼‰
    Args:
        question: ç”¨æˆ·é—®é¢˜
        top_k: æ£€ç´¢å‰ k ä¸ªç›¸å…³æ®µè½
    Returns:
        å¤§æ¨¡å‹åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆçš„è‡ªç„¶è¯­è¨€å›ç­”
    """
    if not is_fitted():
        raise RuntimeError("No documents indexed.")

    texts = get_texts()
    if not texts:
        return "çŸ¥è¯†åº“ä¸ºç©ºã€‚"

    # 1. è·å–æŸ¥è¯¢å‘é‡
    try:
        query_vec = get_embeddings([question])  # (1, 1024)
    except Exception as e:
        return f"âŒ åµŒå…¥ç”Ÿæˆå¤±è´¥ï¼ˆé—®é¢˜ï¼‰: {str(e)}"

    # 2. è·å–æ‰€æœ‰æ–‡æœ¬å‘é‡
    try:
        text_vecs = get_embeddings(texts)       # (n, 1024)
    except Exception as e:
        return f"âŒ åµŒå…¥ç”Ÿæˆå¤±è´¥ï¼ˆæ–‡æ¡£ï¼‰: {str(e)}"

    # 3. è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    sims = cosine_similarity(query_vec, text_vecs)[0]  # (n,)

    # 4. å– top-k æœ€ç›¸ä¼¼çš„æ–‡æœ¬
    top_indices = np.argsort(sims)[-top_k:][::-1]
    relevant_contexts = [texts[i] for i in top_indices]

    # 5. æ‹¼æ¥ä¸Šä¸‹æ–‡
    context = "\n\n---\n\n".join(relevant_contexts).strip()

    # 6. æ„é€  Prompt
    prompt = f"""\
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ©æ‰‹ï¼Œè¯·æ ¹æ®ä»¥ä¸‹æä¾›çš„ä¸Šä¸‹æ–‡å†…å®¹å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

        è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œä¿æŒç®€æ´ã€å‡†ç¡®ã€ä¸“ä¸šã€‚

        <context>
        {context}
        </context>

        <question>
        {question}
        </question>

        <answer>
    """

    # 7. è°ƒç”¨ OpenAI ç”Ÿæˆå›ç­”
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",  # å¯æ”¹ä¸º "gpt-4" å¦‚æœä½ æœ‰æƒé™
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£é—®ç­”åŠ©æ‰‹ï¼ŒåªåŸºäºæä¾›çš„ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯ã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=0.3,
            max_tokens=512,
        )
        # æå–å›ç­”
        answer = response.choices[0].message.content.strip()
        return answer
    except Exception as e:
        return f"âŒ è°ƒç”¨ OpenAI æ—¶å‡ºé”™: {str(e)}"